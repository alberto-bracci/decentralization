{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae1bb710-41ae-4a56-8b1d-e7e9e96fb990",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e9b35632-e6db-4b74-862f-2ad2d28d8cfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_34711/1201694884.py:9: PyGIWarning: Gtk was imported without specifying a version first. Use gi.require_version('Gtk', '3.0') before import to ensure that the right version gets loaded.\n",
      "  from gi.repository import Gtk, Gdk\n"
     ]
    }
   ],
   "source": [
    "import gzip\n",
    "import pickle\n",
    "import joblib\n",
    "\n",
    "from random import choice\n",
    "import scipy.stats\n",
    "import sys\n",
    "import gi\n",
    "from gi.repository import Gtk, Gdk\n",
    "import graph_tool.all as gt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import time\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.feature_extraction import text\n",
    "from nltk.stem import  WordNetLemmatizer\n",
    "import re\n",
    "\n",
    "from datetime import datetime\n",
    "\n",
    "import random\n",
    "import seaborn as sns\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import jsonlines\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import platform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "686c8f7f-e386-49b2-91e9-1a2c6fbeb90c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DEFAULT PARAMETERS IN THE FIGURES TO BE ADJUSTED!!!!\n",
    "\n",
    "plt.style.use(\"default\")\n",
    "\n",
    "height_fig = 5\n",
    "width_fig = 10\n",
    "\n",
    "params_default = {\n",
    "    # no upper and right axes\n",
    "    'axes.spines.right' : False,\n",
    "    'axes.spines.top' : False,\n",
    "    # no frame around the legend\n",
    "    \"legend.frameon\" : False,\n",
    "\n",
    "    # dimensions of figures and labels\n",
    "    # we will play with these once we see how they are rendered in the latex\n",
    "    'figure.figsize' : (width_fig, height_fig),\n",
    "\n",
    "    'axes.labelsize' : 22,\n",
    "    'axes.titlesize' : 25,\n",
    "    'xtick.labelsize' : 18,\n",
    "    'ytick.labelsize' : 18,\n",
    "    'legend.fontsize' : 16,\n",
    "\n",
    "    # no grids (?)\n",
    "    'axes.grid' : False,\n",
    "\n",
    "    # the default color(s) for lines in the plots: in order if multiple lines. We can change them or add colors if needed\n",
    "#     'axes.prop_cycle' : mpl.cycler(color=[\"#00008B\", \"#BF0000\", \"#006400\"]), \n",
    "\n",
    "    # default quality of the plot. Not too high but neither too low\n",
    "    \"savefig.dpi\" : 300,\n",
    "    \"savefig.bbox\" : 'tight', \n",
    "\n",
    "}\n",
    "\n",
    "\n",
    "plt.rcParams.update(params_default)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ef38be8-7971-44ce-bc0d-c9726d11e534",
   "metadata": {},
   "source": [
    "# Collecting data from Corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6496f64-f27b-4620-a443-8fda78562c19",
   "metadata": {},
   "source": [
    "Download corpus from\n",
    "https://api.semanticscholar.org/corpus/download/\n",
    "\n",
    "Corpus download: 2021-09-01 release\n",
    "\n",
    "Commands used:\n",
    "\n",
    "wget https://s3-us-west-2.amazonaws.com/ai2-s2-research-public/open-corpus/2021-09-01/manifest.txt\n",
    "\n",
    "wget -B https://s3-us-west-2.amazonaws.com/ai2-s2-research-public/open-corpus/2021-09-01/ -i manifest.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb084ad-4aaa-4851-9345-10c8746ba787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working on pfsnsq860259\n"
     ]
    }
   ],
   "source": [
    "# move in repo root folder\n",
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7f968bca-c21d-4fe4-9cc0-155175bff763",
   "metadata": {},
   "outputs": [],
   "source": [
    "words_to_check_dict = {'decentralization':[\"centraliz\",\"centralis\"],\n",
    "                  'internet':[\"world-wide-web\", \"world wide web\", \"worldwideweb\", \"worldwide web\",\"worldwide-web\", \"internet\"],\n",
    "                  'virus':[\"virus\"]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "aeb0e177-bed6-47d9-99af-a458ad10b395",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34m2021-09-01\u001b[0m/  \u001b[01;34mdecentralization\u001b[0m/  \u001b[01;34minternet\u001b[0m/  \u001b[01;34mvirus\u001b[0m/\n"
     ]
    }
   ],
   "source": [
    "corpus_version = \"2021-09-01\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "737e4d73-f3a7-4c73-876c-94085b2dc6cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_docs_dict = {key:{} for key in words_to_check_dict}\n",
    "no_papers_in_fields_by_year = {key:{} for key in words_to_check_dict}\n",
    "sets_authors_in_fields_by_year = {key:{} for key in words_to_check_dict}\n",
    "sets_authors_by_year = {key:{} for key in words_to_check_dict}\n",
    "no_authors_in_fields_by_year = {key:{} for key in words_to_check_dict}\n",
    "no_authors_by_year = {key:{} for key in words_to_check_dict}\n",
    "count = 0\n",
    "start = datetime.now()\n",
    "\n",
    "for ID in tqdm(range(6000)):\n",
    "    filename = f\"./corpus/{corpus_version}/s2-corpus-%.3d.gz\"%ID\n",
    "    with gzip.open(filename, \"rb\") as f:\n",
    "        for item in jsonlines.Reader(f):\n",
    "            x=item\n",
    "            count += 1\n",
    "            title = x[\"title\"].lower()\n",
    "            abstract = x[\"paperAbstract\"].lower()\n",
    "           \n",
    "            for keyword,words_to_check in words_to_check_dict.items():\n",
    "                add_it = False\n",
    "                for word in words_to_check:\n",
    "                    if word in title or word in abstract:\n",
    "                        add_it = True\n",
    "                if add_it:\n",
    "                    all_docs_dict[keyword][x[\"id\"]] = x.copy()\n",
    "                year = x[\"year\"]\n",
    "                if year not in no_papers_in_fields_by_year[keyword]:\n",
    "                    no_papers_in_fields_by_year[keyword][year] = {}\n",
    "                    sets_authors_in_fields_by_year[keyword][year] = {}\n",
    "                    sets_authors_by_year[keyword][year] = set()\n",
    "                year_dict = no_papers_in_fields_by_year[keyword][year]\n",
    "                fields = tuple(x[\"fieldsOfStudy\"])\n",
    "                if fields not in year_dict:\n",
    "                    year_dict[fields] = 1\n",
    "                    sets_authors_in_fields_by_year[keyword][year][fields] = set()\n",
    "                else:\n",
    "                    year_dict[fields] += 1\n",
    "                for authors in x[\"authors\"]:\n",
    "                    sets_authors_in_fields_by_year[keyword][year][fields].update(authors[\"ids\"])\n",
    "                    sets_authors_by_year[keyword][year].update(authors[\"ids\"])\n",
    "    end = datetime.now()\n",
    "\n",
    "    if ID%100 == 0:\n",
    "        print(ID,len(all_docs_dict), end-start,flush=True)\n",
    "\n",
    "for keyword in words_to_check_dict:\n",
    "    os.makedirs(\"data/\" + keyword,exist_ok=True)\n",
    "    os.chdir(\"data/\" + keyword)\n",
    "    with gzip.open(\"papers_dict.pkl.gz\", \"wb\") as fp:\n",
    "        pickle.dump(all_docs_dict[keyword],fp)\n",
    "\n",
    "    with gzip.open(\"no_papers_in_fields_by_year.pkl.gz\", \"wb\") as fp:\n",
    "        pickle.dump(no_papers_in_fields_by_year[keyword],fp)\n",
    "\n",
    "    with gzip.open(\"sets_authors_in_fields_by_year.pkl.gz\", \"wb\") as fp:\n",
    "        pickle.dump(sets_authors_in_fields_by_year[keyword],fp)\n",
    "\n",
    "\n",
    "    for year, year_dict in sets_authors_in_fields_by_year[keyword].items():\n",
    "        no_authors_in_fields_by_year[keyword][year] = {}\n",
    "        for fields, set_authors in year_dict.items():\n",
    "            no_authors_in_fields_by_year[keyword][year][fields] = len(set_authors)\n",
    "    with gzip.open(\"no_authors_in_fields_by_year.pkl.gz\", \"wb\") as fp:\n",
    "        pickle.dump(no_authors_in_fields_by_year[keyword],fp)\n",
    "\n",
    "    for year, year_dict in sets_authors_by_year[keyword].items():\n",
    "        no_authors_by_year[keyword][year] = len(year_dict)\n",
    "    with gzip.open(\"no_authors_by_year.pkl.gz\", \"wb\") as fp:\n",
    "        pickle.dump(no_authors_by_year[keyword],fp)\n",
    "    os.chdir(\"../../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c18946-2aa4-4866-b302-cf45c2d16600",
   "metadata": {},
   "outputs": [],
   "source": [
    "for keyword,papers in all_docs_dict.items():\n",
    "    print(f\"keyword: {keyword} - no.papers: {len(papers)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e8722aa-9077-4ab8-adb6-84cd25fb1d28",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "759f87fb-fe1d-4755-bfd4-f7560808734d",
   "metadata": {},
   "source": [
    "# Checks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5aea523a-cb14-4e34-bc71-e63a40a2371c",
   "metadata": {},
   "outputs": [],
   "source": [
    "chosen_keyword = 'decentralization'\n",
    "chosen_dict = all_docs_dict[chosen_keyword]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d0d5e958-b76e-46d9-a59c-3b54a58365c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 715\n"
     ]
    }
   ],
   "source": [
    "bad = []\n",
    "count = 0\n",
    "count_all = 0\n",
    "for key, paper in chosen_dict.items():\n",
    "    title = paper[\"title\"]\n",
    "    abstract = paper[\"paperAbstract\"]\n",
    "    if \"centralized\" not in title and \"centralised\" not in title and \"centralization\" not in title and \"centralisation\" not in title and \"centralized\" not in abstract and \"centralised\" not in abstract and \"centralization\" not in abstract and \"centralisation\" not in abstract:\n",
    "        count += 1\n",
    "        bad.append(paper[\"id\"])\n",
    "    count_all += 1\n",
    "print(count, count_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "def251e6-fb9e-4bfd-8681-2b86104520f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'id': 'f842293e6e6ce4f328e7b89b169a0027a2dd1f52',\n",
       " 'title': 'Modèles de développement en Guadeloupe et intégration européenne',\n",
       " 'paperAbstract': 'Le but de cette these est d\\'etudier la question du developpement et du phenomene de la dependance d\\'une societe peripherique particuliere, la guadeloupe, dans le contexte de l\\'integration europeenne. La premiere partie presente cette methodologie de la recherche: c\\'est en fait la preparation qualitative pour un passage du \"general\" au \"particulier\" dans un souci de depassament des prenotions. La deuxieme partie traite de la mise en place du systeme colonial et de la legitimation des rapports esclavagistes. La troisieme partie presente la transformation du statut de \"colonie\" au \"departement\" de la guadeloupe. Dans la quatrieme partie, ilest question du modele decentralisateur avec la loi de 1982. Et enfin, la cinquieme partie fait reference aux propositions explicatives a dimension theorique.',\n",
       " 'authors': [{'name': 'Rosan  Rauzduel', 'ids': ['123717681']}],\n",
       " 'inCitations': [],\n",
       " 'outCitations': [],\n",
       " 'year': 1994,\n",
       " 's2Url': 'https://semanticscholar.org/paper/f842293e6e6ce4f328e7b89b169a0027a2dd1f52',\n",
       " 'sources': [],\n",
       " 'pdfUrls': [],\n",
       " 'venue': '',\n",
       " 'journalName': '',\n",
       " 'journalVolume': '',\n",
       " 'journalPages': '',\n",
       " 'doi': '',\n",
       " 'doiUrl': '',\n",
       " 'pmid': '',\n",
       " 'fieldsOfStudy': ['Political Science'],\n",
       " 'magId': '2206340156',\n",
       " 's2PdfUrl': '',\n",
       " 'entities': []}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chosen_dict[bad[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1a04dab-45d9-483d-ae56-60e2c108d21b",
   "metadata": {},
   "source": [
    "## Counting how many papers have each attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c0e9a2-765c-4880-82d7-9f22a966c133",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_doi = []\n",
    "count_doi = 0\n",
    "for paper, paper_dict in chosen_dict.items():\n",
    "    if paper_dict[\"doi\"] is None or len(paper_dict[\"doi\"]) == 0:\n",
    "        no_doi.append(paper)\n",
    "    else:\n",
    "        count_doi += 1\n",
    "print(f\"{count_doi} have doi of total {len(chosen_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "35439a9b-4036-476a-92c1-9dbd51e266c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "392786 have year of total 394126\n"
     ]
    }
   ],
   "source": [
    "no_year = []\n",
    "count_year = 0\n",
    "for paper, paper_dict in chosen_dict.items():\n",
    "    if paper_dict[\"year\"] is None:\n",
    "        no_year.append(paper)\n",
    "    else:\n",
    "        count_year += 1\n",
    "print(f\"{count_year} have year of total {len(chosen_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "1ab7810e-5cb7-45bd-8d12-862288d342eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "357081 have fields of total 394126\n"
     ]
    }
   ],
   "source": [
    "no_fields = []\n",
    "count_fields = 0\n",
    "for paper, paper_dict in chosen_dict.items():\n",
    "    if paper_dict[\"fieldsOfStudy\"] is None or len(paper_dict[\"fieldsOfStudy\"]) == 0:\n",
    "        no_year.append(paper)\n",
    "    else:\n",
    "        count_fields += 1\n",
    "print(f\"{count_fields} have fields of total {len(chosen_dict)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "a610d13c-95ac-417e-aba1-5c1c39bb8ee1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "191065 are good of total 394126 (have doi, year, fields, abstract, title, and at least one of reference or citation)\n"
     ]
    }
   ],
   "source": [
    "no_good = []\n",
    "count_good = 0\n",
    "for paper, paper_dict in chosen_dict.items():\n",
    "    if paper_dict[\"doi\"] is None or len(paper_dict[\"doi\"]) == 0 or paper_dict[\"year\"] is None or paper_dict[\"fieldsOfStudy\"] is None or len(paper_dict[\"fieldsOfStudy\"]) == 0 or paper_dict[\"paperAbstract\"] is None or len(paper_dict[\"paperAbstract\"]) == 0 or paper_dict[\"title\"] is None or len(paper_dict[\"title\"]) == 0 or ( len(paper_dict[\"inCitations\"]) == 0 and len(paper_dict[\"outCitations\"]) == 0 ):\n",
    "        no_good.append(paper)\n",
    "    else:\n",
    "        count_good += 1\n",
    "print(f\"{count_good} are good of total {len(chosen_dict)} (have doi, year, fields, abstract, title, and at least one of reference or citation)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438fb998-6255-492b-9816-f5221dd512a2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
